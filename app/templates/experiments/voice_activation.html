<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Voice Activity Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        button { font-size: 1em; padding: 10px 20px; margin: 10px 0; }
        #status, #result { margin-top: 20px; padding: 10px; border: 1px solid #ddd; min-height: 50px; }
        #audioVisualizer { width: 100%; height: 100px; background-color: #f0f0f0; margin-top: 20px; }
    </style>
</head>
<body>
    <h1>Interactive Voice Activity Detection</h1>
    <button id="startButton">Start VAD</button>
    <button id="stopButton" disabled>Stop VAD</button>
    <div id="status">Status: Idle</div>
    <div id="result">Detection Results:</div>
    <canvas id="audioVisualizer"></canvas>

    <script>
        let myvad;
        let isRunning = false;
        let audioContext;
        let analyser;
        let dataArray;
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusDiv = document.getElementById('status');
        const resultDiv = document.getElementById('result');
        const canvas = document.getElementById('audioVisualizer');
        const canvasCtx = canvas.getContext('2d');

        async function setupVAD() {
            myvad = await vad.MicVAD.new({
                onSpeechStart: () => {
                    console.log("Speech start detected");
                    statusDiv.textContent = "Status: Speech Detected";
                    resultDiv.innerHTML += "<p>Speech started</p>";
                },
                onSpeechEnd: (audio) => {
                    console.log("Speech end detected");
                    statusDiv.textContent = "Status: Listening";
                    resultDiv.innerHTML += "<p>Speech ended (duration: " + (audio.length / 16000).toFixed(2) + "s)</p>";
                    // You can do something with the audio data here if needed
                },
                onVADMisfire: () => {
                    console.log("VAD misfire");
                    statusDiv.textContent = "Status: VAD Misfire";
                }
            });
        }

        function setupAudioVisualizer() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            const bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    const source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);
                    visualize();
                })
                .catch(err => console.error('Error accessing microphone:', err));
        }

        function visualize() {
            const WIDTH = canvas.width;
            const HEIGHT = canvas.height;

            requestAnimationFrame(visualize);

            analyser.getByteTimeDomainData(dataArray);

            canvasCtx.fillStyle = 'rgb(200, 200, 200)';
            canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

            canvasCtx.beginPath();

            const sliceWidth = WIDTH * 1.0 / dataArray.length;
            let x = 0;

            for (let i = 0; i < dataArray.length; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * HEIGHT / 2;

                if (i === 0) {
                    canvasCtx.moveTo(x, y);
                } else {
                    canvasCtx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            canvasCtx.lineTo(canvas.width, canvas.height / 2);
            canvasCtx.stroke();
        }

        startButton.addEventListener('click', async () => {
            if (!myvad) {
                await setupVAD();
            }
            if (!audioContext) {
                setupAudioVisualizer();
            }
            myvad.start();
            isRunning = true;
            startButton.disabled = true;
            stopButton.disabled = false;
            statusDiv.textContent = "Status: Listening";
        });

        stopButton.addEventListener('click', () => {
            if (myvad && isRunning) {
                myvad.stop();
                isRunning = false;
                startButton.disabled = false;
                stopButton.disabled = true;
                statusDiv.textContent = "Status: Stopped";
            }
        });
    </script>
</body>
</html>